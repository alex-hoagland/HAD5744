################################################################################
mydata <- readxl::read_xlsx(here("HealthExpenses.xlsx"))
# Main (binary) outcome: who has coverage?
m1 <- lm(coverage ~ age + sex + bmi + children + smoker,data=mydata)
msummary(list("LPM"=m1),
vcov=c("robust"),
stars=c('*' = .1, '**' = .05, '***' = .01))
# Look at predictions
mydata$pred_coverage <- predict(m1, mydata)
hist(mydata$pred_coverage) # what problems do you see here?
summary(mydata) # First problem: some predictions are outside of the unit interval!
mydata %>% filter(pred_coverage > 1.14) # What does it mean to have a 114% probability of having coverage?
hist(mydata$pred_coverage) # Second problem: how do you go from a predicted 57% probability of Y=1 to predicting Y?
mydata <- mydata %>% mutate(yhat = ifelse(pred_coverage >= 0.5, 1, 0)) # What happens if we assume a cutoff (Yhat >= 50% means Yhat = 1)? How good is our match then?
table(mydata$coverage, mydata$yhat) # We incorrectly match 34% of the data!
# Logit
m2 <- glm(coverage ~ age + sex + bmi + children + smoker,data=mydata,
family='binomial'(link='logit')) # since we have binary data
# Probit
m3 <- glm(coverage ~ age + sex + bmi + children + smoker,data=mydata,
family='binomial'(link='probit')) # since we have binary data
msummary(list("LPM"=m1,"Logit"=m2,"Probit"=m3),
vcov=c(rep("robust",3)),
stars=c('*' = .1, '**' = .05, '***' = .01))
# Fitted regression "lines"
library(ggdist) # Cool extensions for ggplot
ggplot(mydata,aes(x=bmi,y=coverage))+
geom_dots(aes(side=ifelse(coverage == 1, "bottom", "top")),
pch=19, color="gray70", scale=0.2) +
geom_smooth(method="glm", method.args = list(family = binomial(link = "logit")),
size=1, color='green', se = FALSE)
# Another option: coefplot
library(coefplot)
coefplot(m1,m2) + theme_classic() + labs(x="Log(Odds) Coefficient", y="Variable")
coefplot(m1,m2) + theme_classic() + labs(x="Log(Odds) Coefficient", y="Variable")
coefplot(m2) + theme_classic() + labs(x="Log(Odds) Coefficient", y="Variable")
?coefplot
coefplot(m2,intercept=FALSE) + theme_classic() + labs(x="Log(Odds) Coefficient", y="Variable")
coefplot(m2,intercept=FALSE,innerCI=0) +
theme_classic() + labs(x="Log(Odds) Coefficient", y="Variable")
coefplot(m2,intercept=FALSE,innerCI=0,ci_level = 0.90,) +
theme_classic() + labs(x="Log(Odds) Coefficient", y="Variable")
coefplot(m2,intercept=FALSE,innerCI=0,ci_level = 0.99,) +
theme_classic() + labs(x="Log(Odds) Coefficient", y="Variable")
coefplot(m2,intercept=FALSE,innerCI=0,ci_level = 0.999,) +
theme_classic() + labs(x="Log(Odds) Coefficient", y="Variable")
coefplot(m2,intercept=FALSE,innerCI=0,ci_level = 0.999,trans=invlogit) +
theme_classic() + labs(x="Log(Odds) Coefficient", y="Variable")
coefplot(m1) # coefplot of LPM
coefplot(m1,intercept=F) + theme_classic() # coefplot of LPM
summary(m1)
coefplot(m1,intercept=F, ci.width=.05) + theme_classic() # coefplot of LPM. Why do we like this?
coefplot(m1,intercept=F, ci.width=.0001) + theme_classic() # coefplot of LPM. Why do we like this?
coefplot(m1,intercept=F, ci.width=.0000001) + theme_classic() # coefplot of LPM. Why do we like this?
coefplot(m1,intercept=F, ci.width=.0000001, ci.fill='green') + theme_classic() # coefplot of LPM. Why do we like this?
coefplot(m1, ci.width=1)
coefplot(m1, ci.width=100)
coefplot(m1, ci.width=100000)
coefplot(m1, ci.width=1e-8)
coefplot(m1, innerCI=.01)
coefplot(m1, innerCI=100)
# Another option: coefplot (useful in many settings! )
library(fixest)
coefplot(m1,intercept=F, ci.width=.0000001, ci.fill='green') + theme_classic() # coefplot of LPM. Why do we like this?
coefplot(m1,intercept=F, ci.width=.0000001) + theme_classic() # coefplot of LPM. Why do we like this?
?coefplot
fixest::coefplot(m1,intercept=F) + theme_classic() # coefplot of LPM. Why do we like this?
fixest::coefplot(m1,drop = "Intercept") + theme_classic() # coefplot of LPM. Why do we like this?
# Now, let's do coefplot of logit
fixest::coefplot(m2,drop = "Intercept") +
theme_classic() + labs(x="Log(Odds) Coefficient", y="Variable")
# Now, let's do coefplot of logit
fixest::coefplot(m2,drop = "Intercept") +
theme_classic()
coefplot::coefplot(m2,intercept=FALSE,innerCI=2,outerCI=0,trans=invlogit) +
theme_classic() + labs(x="Log(Odds) Coefficient", y="Variable")
?fixest
m2 <- feglm(coverage ~ age + sex + bmi + children + smoker,data=mydata,
family='binomial'(link='logit')) # since we have binary data
# Probit
m3 <- feglm(coverage ~ age + sex + bmi + children + smoker,data=mydata,
family='binomial'(link='probit')) # since we have binary data
msummary(list("LPM"=m1,"Logit"=m2,"Probit"=m3),
vcov=c(rep("robust",3)),
stars=c('*' = .1, '**' = .05, '***' = .01))
ggplot(mydata,aes(x=bmi,y=coverage))+
geom_dots(aes(side=ifelse(coverage == 1, "bottom", "top")),
pch=19, color="gray70", scale=0.2) +
geom_smooth(method="glm", method.args = list(family = binomial(link = "logit")),
size=1, color='green', se = FALSE) +
labs(x="BMI", y="Pr(Coverage)")
fixest::coefplot(m1,drop = "Intercept") + theme_classic() # coefplot of LPM. Why do we like this?
# Now, let's do coefplot of logit
fixest::coefplot(m2,drop = "Intercept") + theme_classic()
# 1. Each individual marginal effect
allmarginaleffects <- marginaleffects(m2) # Gives you individual ME for all variables/observations
View(allmarginaleffects)
hist(allmarginaleffects$dydx)
ggplot(allmarginaleffects, aes(x=dydx)) + geom_histogram(aes(fill=p.value))
# 1. Each individual marginal effect
allmarginaleffects <- marginaleffects(m2) # Gives you individual ME for all variables/observations
allmarginaleffects %>% mutate(bin = ifelse(p.value > 0.1, 0,
ifelse(p.value <= 0.1 & p.value > 0.05, 1,
ifelse(p.value <= 0.05 & p.value > 0.01, 2, 3))))
allmarginaleffects <- allmarginaleffects %>% mutate(bin = ifelse(p.value > 0.1, 0,
ifelse(p.value <= 0.1 & p.value > 0.05, 1,
ifelse(p.value <= 0.05 & p.value > 0.01, 2, 3))))
ggplot(allmarginaleffects, aes(x=dydx)) + geom_histogram(aes(fill=as.factor(bin)))
ggplot(allmarginaleffects, aes(x=dydx)) +
geom_histogram(aes(fill=as.factor(bin))) +
theme_classic() +
labs(x="Marginal Effect", y = "Value", fill = "Significance")
# 2. and 4. MER and MEM: use the datagrid() function
summary(marginaleffects(m2, datagrid(age  =50, sex = "male", bmi = 50, children = 0, smoker = 1, grid.type = 'counterfactual')))
# 3. AME
summary(marginaleffects(m2)) # This gives you AME
plot(marginaleffects(m2)) # Convenience plot
# 4. MEM:
summary(marginaleffects(m2, datagrid()))
# Full model is m2 -- already estimated
restricted <- glm(coverage ~ bmi + children + smoker,data=mydata,
family='binomial'(link='logit')) # Restricted model is where age and sex are both 0
lmtest::waldtest(m2,restricted)
# Full model is m2 -- already estimated
restricted <- feglm(coverage ~ bmi + children + smoker,data=mydata,
family='binomial'(link='logit')) # Restricted model is where age and sex are both 0
lmtest::waldtest(m2,restricted)
load("C:/Users/alexh/Downloads/surveydata.xlsx")
library(xlsx)
library(readxl)
read_excel(""C:\Users\alexh\Downloads\surveydata.xlsx"")
read_excel("C:\Users\alexh\Downloads\surveydata.xlsx")
mydata <- read_excel("C:\\Users\\alexh\\Downloads\\surveydata.xlsx")
View(mydata)
names(mydata) <- c("Q","name","score","program","resp")
library(tidyverse)
summ <- mydata %>% group_by(Q,program) %>% summarize(score = mean(score), sd = sd(score), n = n())
View(summ)
summ <- mydata %>% group_by(Q,program) %>% summarize(score = mean(score, na.rm=T), sd = sd(score, na.rm=T), n = n())
summ <- mydata %>% group_by(Q,program) %>% summarize(mean = mean(score, na.rm=T), sd = sd(score, na.rm=T), n = n())
summ <- mydata %>% group_by(program) %>% summarize(mean = mean(score, na.rm=T), sd = sd(score, na.rm=T), n = n())
summ <- summ %>% mutate(se = sd / sqrt(n)) %>% mutate(lb = mean - 1.96*se, ub = mean + 1.96*se)
vec1 <- mydata %>% filter(program == "ACA") %>% select(score)
vec1
vec2 <- mydata %>% filter(program == "MA") %>% select(score)
t.test(vec1,vec2)
summ <- mydata %>% group_by(Q,program) %>% summarize(mean = mean(score, na.rm=T), sd = sd(score, na.rm=T), n = n()) %>% mutate(se = sd/sqrt(n)) %>% mutate(lb = mean - 1.96*se, ub = mean + 1.96*se)
knitr::opts_chunk$set(echo = TRUE)
################################################################################
# I like to include several additional notes in the header of my files here:
#
# Last modified: 8/12/2022
#
### PURPOSE:
# Lectures 7 and 8 code and output file
#
### NOTES:
# - uses the Tidyverse package and Dplyr
################################################################################
### 0. Load the packages we will need for this file ####
library(tidyverse) # load the installed package for each new session of R
library(broom)
library(readxl) # Read in data
library(modelsummary) # For making regression tables
library(causaldata) # Useful toy data sets
library(here) # Helpful in working with directories and projects
library(AER) # this package has lots of applied metrics packages
library(foreign) # Helpful for reading in data from Stata or other code languages
library(devtools)
install_github("vincentarelbundock/marginaleffects")
library(marginaleffects) # To calculate marginal effects
library(pscl) # For hurdle models
library(nnet) # For multinomial logit models
library(knitr) # Alternative table package
library(kableExtra) # Alternative table package
library(gtsummary) # Alternative table package
set.seed(03262020)
FFTrees::blood
mydata <- FFTrees::blood
mydata %>% summary()
# Main (binary) outcome: who has coverage?
m1 <- lm(donation.crit ~ recency + frequency + total + time,data=mydata)
msummary(list("LPM"=m1),
vcov=c("robust"),
stars=c('*' = .1, '**' = .05, '***' = .01))
# Main (binary) outcome: who has coverage?
m1 <- lm(donation.crit ~ recency + frequency + total + time, data=mydata)
msummary(list("LPM"=m1),
vcov=c("robust"),
stars=c('*' = .1, '**' = .05, '***' = .01))
?FFTrees::blood
summary(m1)
mydata$total
sum(is.na(mydata$total))
mydata %>% summary() %>% rename("total_donated" = "total")
mydata %>% summary() %>% rename(total_donated = total)
mydata %>% summary() %>% dplyr::rename(total_donated = total)
mydata <- FFTrees::blood # data on blood donation
mydata <- mydata %>% rename(total_donated = total)
mydata %>% summary()
# Main (binary) outcome: who has coverage?
m1 <- lm(donation.crit ~ recency + frequency + total_donated + time, data=mydata)
msummary(list("LPM"=m1),
vcov=c("robust"),
stars=c('*' = .1, '**' = .05, '***' = .01))
View(mydata)
# Main (binary) outcome: who has coverage?
m1 <- lm(donation.crit ~ recency + frequency + time, data=mydata)
msummary(list("LPM"=m1),
vcov=c("robust"),
stars=c('*' = .1, '**' = .05, '***' = .01))
# Effect sizes in context?
# Note: each month of recency is associated with a 1 percentage point decline in the likelihood of donating. How relevant is that?
mydata %>% select(donation.crit) %>% summarize(mean = mean())
# Effect sizes in context?
# Note: each month of recency is associated with a 1 percentage point decline in the likelihood of donating. How relevant is that?
mydata %>% select(donation.crit) %>% summarize(mean = mean(donation.crit), sd = sd(donation.crit)) # 26% of people donated in March 2007
# Effect sizes in context?
# Note: each month of recency is associated with a 1 percentage point decline in the likelihood of donating. How relevant is that?
mydata %>% select(donation.crit) %>% summarize(mean = mean(donation.crit)) %>%
mutate(percentage_change = -.01/mean * 100)
# Look at predictions
mydata$pred_donation <- predict(m1, mydata)
hist(mydata$pred_coverage) # what problems do you see here?
hist(mydata$pred_donation) # what problems do you see here?
summary(mydata) # First problem: some predictions are outside of the unit interval!
mydata %>% filter(pred_coverage > 1.1) # What does it mean to have a 110% probability of donating?
mydata %>% filter(pred_donation > 1.1) # What does it mean to have a 110% probability of donating?
hist(mydata$pred_donation) # Second problem: how do you go from a predicted 57% probability of Y=1 to predicting Y?
mydata <- mydata %>% mutate(yhat = ifelse(pred_donation >= 0.5, 1, 0)) # What happens if we assume a cutoff (Yhat >= 50% means Yhat = 1)? How good is our match then?
table(mydata$coverage, mydata$yhat) # We incorrectly match 34% of the data!
table(mydata$donation.crit, mydata$pred_donation) # We incorrectly match 34% of the data!
table(mydata$donation.crit, mydata$yhat) # We incorrectly match 34% of the data!
169/748
mydata %>% summary()
mydata <- mydata %>% mutate(yhat = ifelse(pred_donation >= 0.25, 1, 0)) # What happens if we assume a cutoff (Yhat >= 50% means Yhat = 1)? How good is our match then?
table(mydata$donation.crit, mydata$yhat) # We incorrectly match 22.6% of the data! And we only predict a few donations. Can we play around with this (lower thresholds?)
mydata <- mydata %>% mutate(yhat = ifelse(pred_donation >= 0.35, 1, 0)) # What happens if we assume a cutoff (Yhat >= 50% means Yhat = 1)? How good is our match then?
table(mydata$donation.crit, mydata$yhat) # We incorrectly match 22.6% of the data! And we only predict a few donations. Can we play around with this (lower thresholds?)
mydata <- mydata %>% mutate(yhat = ifelse(pred_donation >= 0.5, 1, 0)) # What happens if we assume a cutoff (Yhat >= 50% means Yhat = 1)? How good is our match then?
table(mydata$donation.crit, mydata$yhat) # We incorrectly match 22.6% of the data! And we only predict a few donations. Can we play around with this (lower thresholds?)
# Logit
library(fixest)
m2 <- feglm(donation.crit ~ recency + frequency + time, data=mydata,
family='binomial'(link='logit')) # since we have binary data
# Probit
m3 <- feglm(donation.crit ~ recency + frequency + time, data=mydata,
family='binomial'(link='probit')) # since we have binary data
msummary(list("LPM"=m1,"Logit"=m2,"Probit"=m3),
vcov=c(rep("robust",3)),
stars=c('*' = .1, '**' = .05, '***' = .01))
# Fitted regression "lines"
library(ggdist) # Cool extensions for ggplot
ggplot(mydata,aes(x=recency,y=donation.crit))+
geom_dots(aes(side=ifelse(coverage == 1, "bottom", "top")),
pch=19, color="gray70", scale=0.2) +
geom_smooth(method="glm", method.args = list(family = binomial(link = "logit")),
size=1, color='green', se = FALSE) +
labs(x="Months since last donation", y="Pr(Donates)")
ggplot(mydata,aes(x=recency,y=donation.crit))+
geom_dots(aes(side=ifelse(donation.crit == 1, "bottom", "top")),
pch=19, color="gray70", scale=0.2) +
geom_smooth(method="glm", method.args = list(family = binomial(link = "logit")),
size=1, color='green', se = FALSE) +
labs(x="Months since last donation", y="Pr(Donates)")
fixest::coefplot(m1,drop = "Intercept") + theme_classic() # coefplot of LPM. Why do we like this?
fixest::coefplot(m1,drop = "Constant") + theme_classic() # coefplot of LPM. Why do we like this?
# Now, let's do coefplot of logit
fixest::coefplot(m2,drop = "Intercept") + theme_classic()
# Now, let's do coefplot of logit
fixest::coefplot(m2,drop = "Constant") + theme_classic()
knitr::opts_chunk$set(echo = TRUE)
mydata <- FFTrees::blood # data on blood donation
mydata <- mydata %>% rename(total_donated = total)
################################################################################
# I like to include several additional notes in the header of my files here:
#
# Last modified: 8/12/2022
#
### PURPOSE:
# Lectures 7 and 8 code and output file
#
### NOTES:
# - uses the Tidyverse package and Dplyr
################################################################################
### 0. Load the packages we will need for this file ####
library(tidyverse) # load the installed package for each new session of R
library(broom)
library(readxl) # Read in data
library(modelsummary) # For making regression tables
library(causaldata) # Useful toy data sets
library(here) # Helpful in working with directories and projects
library(AER) # this package has lots of applied metrics packages
library(foreign) # Helpful for reading in data from Stata or other code languages
library(devtools)
library(marginaleffects) # To calculate marginal effects
library(pscl) # For hurdle models
library(nnet) # For multinomial logit models
library(knitr) # Alternative table package
library(kableExtra) # Alternative table package
library(gtsummary) # Alternative table package
set.seed(03262020)
# Setting the seed helps to make random number generators give us the same numbers across machines
################################################################################
mydata <- FFTrees::blood # data on blood donation
mydata <- mydata %>% rename(total_donated = total)
mydata %>% summary()
# Main (binary) outcome: did they donate in March 2007
m1 <- lm(donation.crit ~ recency + frequency + time, data=mydata)
# how to interpret the recency dummy?
msummary(list("LPM"=m1),
vcov=c("robust"),
stars=c('*' = .1, '**' = .05, '***' = .01))
# Effect sizes in context?
# Note: each month of recency is associated with a 1 percentage point decline in the likelihood of donating. How relevant is that?
mydata %>% select(donation.crit) %>% summarize(mean = mean(donation.crit)) %>%
mutate(percentage_change = -.01/mean * 100) # What does this mean in context?
# Alternate example: Insurance coverage as a function of enrollee age, sex, BMI, smoker status, and the number of children in the home. Let's estimate and interpret the LPM.
# mydata <- readxl::read_xlsx(here("HealthExpenses.xlsx"))
#
# # Main (binary) outcome: who has coverage?
# m1 <- lm(coverage ~ age + sex + bmi + children + smoker,data=mydata)
# msummary(list("LPM"=m1),
#          vcov=c("robust"),
#          stars=c('*' = .1, '**' = .05, '***' = .01))
# Look at predictions
mydata$pred_donation <- predict(m1, mydata)
hist(mydata$pred_donation) # what problems do you see here?
summary(mydata) # First problem: some predictions are outside of the unit interval!
mydata %>% filter(pred_donation > 1.1) # What does it mean to have a 110% probability of donating?
hist(mydata$pred_donation) # Second problem: how do you go from a predicted 57% probability of Y=1 to predicting Y?
mydata <- mydata %>% mutate(yhat = ifelse(pred_donation >= 0.5, 1, 0)) # What happens if we assume a cutoff (Yhat >= 50% means Yhat = 1)? How good is our match then?
table(mydata$donation.crit, mydata$yhat) # We incorrectly match 22.6% of the data! And we only predict a few donations. Can we play around with this (lower thresholds?)
# Logit
library(fixest)
m2 <- feglm(donation.crit ~ recency + frequency + time, data=mydata,
family='binomial'(link='logit')) # since we have binary data
# Probit
m3 <- feglm(donation.crit ~ recency + frequency + time, data=mydata,
family='binomial'(link='probit')) # since we have binary data
msummary(list("LPM"=m1,"Logit"=m2,"Probit"=m3),
vcov=c(rep("robust",3)),
stars=c('*' = .1, '**' = .05, '***' = .01))
# Fitted regression "lines"
library(ggdist) # Cool extensions for ggplot
ggplot(mydata,aes(x=recency,y=donation.crit))+
geom_dots(aes(side=ifelse(donation.crit == 1, "bottom", "top")),
pch=19, color="gray70", scale=0.2) +
geom_smooth(method="glm", method.args = list(family = binomial(link = "logit")),
size=1, color='green', se = FALSE) +
labs(x="Months since last donation", y="Pr(Donates)")
# Another option: coefplot (useful in many settings! )
library(fixest) # note: do not use the coefplot library! Much harder to use!
fixest::coefplot(m1,drop = "Constant") + theme_classic() # coefplot of LPM. Why do we like this?
# Now, let's do coefplot of logit
fixest::coefplot(m2,drop = "Constant") + theme_classic()
# See below for coefplot once converted to marginal effects
# 1. Each individual marginal effect
allmarginaleffects <- marginaleffects(m2) # Gives you individual ME for all variables/observations
allmarginaleffects <- allmarginaleffects %>% mutate(bin = ifelse(p.value > 0.1, 0,
ifelse(p.value <= 0.1 & p.value > 0.05, 1,
ifelse(p.value <= 0.05 & p.value > 0.01, 2, 3))))
ggplot(allmarginaleffects, aes(x=dydx)) +
geom_histogram(aes(fill=as.factor(bin))) +
theme_classic() +
labs(x="Marginal Effect", y = "Value", fill = "Significance")
# Full model is m2 -- already estimated
restricted <- feglm(coverage ~ bmi + children + smoker,data=mydata,
family='binomial'(link='logit'))
View(allmarginaleffects)
unique(allmarginaleffects$term)
allmarginaleffects %>% filter(term == "recency") %>%
ggplot(aes(x=dydx)) +
geom_histogram(aes(fill=as.factor(bin))) +
theme_classic() +
labs(x="Marginal Effect", y = "Value", fill = "Significance")
allmarginaleffects %>% filter(term == "recency") %>%
ggplot(aes(x=estimate)) +
geom_histogram(aes(fill=as.factor(bin))) +
theme_classic() +
labs(x="Marginal Effect", y = "Value", fill = "Significance")
allmarginaleffects %>% filter(term == "recency") %>%
ggplot(aes(x=estimate)) +
geom_histogram(aes(fill='blue')) +
theme_classic() +
labs(x="Marginal Effect", y = "Value", fill = "Significance")
allmarginaleffects %>% filter(term == "recency") %>%
ggplot(aes(x=estimate)) +
geom_histogram(fill='blue') +
theme_classic() +
labs(x="Marginal Effect", y = "Value", fill = "Significance")
allmarginaleffects %>% filter(term == "recency") %>%
ggplot(aes(x=estimate)) +
geom_histogram(alpha=0.4, line='blue') +
theme_classic() +
labs(x="Marginal Effect", y = "Value", fill = "Significance")
allmarginaleffects %>% filter(term == "recency") %>%
ggplot(aes(x=estimate)) +
geom_histogram(alpha=0.4, fill='blue') +
theme_classic() +
labs(x="Marginal Effect", y = "Value", fill = "Significance")
allmarginaleffects %>% filter(term == "recency") %>%
ggplot(aes(x=estimate)) +
geom_histogram(alpha=0.4, fill='blue', color='blue') +
theme_classic() +
labs(x="Marginal Effect", y = "Value", fill = "Significance")
mydata %>% select(recency) %>% summarize()
mydata %>% select(recency)
mydata %>% select(recency) %>% summary()
mydata %>% select(frequency) %>% summary()
mydata %>% select(time) %>% summary()
# 2. and 4. MER and MEM: use the datagrid() function
summary(marginaleffects(m2, datagrid(recency = 7, frequency = 4, time = 31, grid.type = 'counterfactual')))
# 4. MEM:
summary(marginaleffects(m2, datagrid()))
# 3. AME
summary(marginaleffects(m2)) # This gives you AME
plot(marginaleffects(m2)) # Convenience plot
plot_slopes(marginaleffects(m2)) # Convenience plot
?plot_slopes
knitr::opts_chunk$set(echo = TRUE)
################################################################################
# I like to include several additional notes in the header of my files here:
#
# Last modified: 8/12/2022
#
### PURPOSE:
# Lectures 7 and 8 code and output file
#
### NOTES:
# - uses the Tidyverse package and Dplyr
################################################################################
### 0. Load the packages we will need for this file ####
library(tidyverse) # load the installed package for each new session of R
library(broom)
library(readxl) # Read in data
library(modelsummary) # For making regression tables
library(causaldata) # Useful toy data sets
library(here) # Helpful in working with directories and projects
library(AER) # this package has lots of applied metrics packages
library(foreign) # Helpful for reading in data from Stata or other code languages
library(devtools)
library(marginaleffects) # To calculate marginal effects
library(pscl) # For hurdle models
library(nnet) # For multinomial logit models
library(knitr) # Alternative table package
library(kableExtra) # Alternative table package
library(gtsummary) # Alternative table package
set.seed(03262020)
# Setting the seed helps to make random number generators give us the same numbers across machines
################################################################################
mydata <- FFTrees::blood # data on blood donation
mydata <- mydata %>% rename(total_donated = total)
mydata %>% summary()
# Main (binary) outcome: did they donate in March 2007
m1 <- lm(donation.crit ~ recency + frequency + time, data=mydata)
# how to interpret the recency dummy?
msummary(list("LPM"=m1),
vcov=c("robust"),
stars=c('*' = .1, '**' = .05, '***' = .01))
# Effect sizes in context?
# Note: each month of recency is associated with a 1 percentage point decline in the likelihood of donating. How relevant is that?
mydata %>% select(donation.crit) %>% summarize(mean = mean(donation.crit)) %>%
mutate(percentage_change = -.01/mean * 100) # What does this mean in context?
# Alternate example: Insurance coverage as a function of enrollee age, sex, BMI, smoker status, and the number of children in the home. Let's estimate and interpret the LPM.
# mydata <- readxl::read_xlsx(here("HealthExpenses.xlsx"))
#
# # Main (binary) outcome: who has coverage?
# m1 <- lm(coverage ~ age + sex + bmi + children + smoker,data=mydata)
# msummary(list("LPM"=m1),
#          vcov=c("robust"),
#          stars=c('*' = .1, '**' = .05, '***' = .01))
?FFTrees
# Logit
library(fixest)
m2 <- feglm(donation.crit ~ recency + frequency + time, data=mydata,
family='binomial'(link='logit')) # since we have binary data
# Probit
m3 <- feglm(donation.crit ~ recency + frequency + time, data=mydata,
family='binomial'(link='probit')) # since we have binary data
msummary(list("LPM"=m1,"Logit"=m2,"Probit"=m3),
vcov=c(rep("robust",3)),
stars=c('*' = .1, '**' = .05, '***' = .01))
# Fitted regression "lines"
library(ggdist) # Cool extensions for ggplot
ggplot(mydata,aes(x=recency,y=donation.crit))+
geom_dots(aes(side=ifelse(donation.crit == 1, "bottom", "top")),
pch=19, color="gray70", scale=0.2) +
geom_smooth(method="glm", method.args = list(family = binomial(link = "logit")),
size=1, color='green', se = FALSE) +
labs(x="Months since last donation", y="Pr(Donates)")
# Another option: coefplot (useful in many settings! )
library(fixest) # note: do not use the coefplot library! Much harder to use!
fixest::coefplot(m1,drop = "Constant") + theme_classic() # coefplot of LPM. Why do we like this?
# Now, let's do coefplot of logit
fixest::coefplot(m2,drop = "Constant") + theme_classic()
# See below for coefplot once converted to marginal effects
# 1. Each individual marginal effect
allmarginaleffects <- marginaleffects(m2) # Gives you individual ME for all variables/observations
allmarginaleffects <- allmarginaleffects %>%
mutate(bin = ifelse(p.value > 0.1, 0,
ifelse(p.value <= 0.1 & p.value > 0.05, 1,
ifelse(p.value <= 0.05 & p.value > 0.01, 2, 3))))
allmarginaleffects %>% filter(term == "recency") %>%
ggplot(aes(x=estimate)) +
geom_histogram(alpha=0.4, fill='blue', color='blue') +
theme_classic() +
labs(x="Marginal Effect", y = "Value", fill = "Significance")
# 3. AME
summary(marginaleffects(m2)) # This gives you AME
# 2. and 4. MER and MEM: use the datagrid() function
summary(marginaleffects(m2, datagrid(recency = 7, frequency = 4, time = 31, grid.type = 'counterfactual')))
