---
title: "Lecture 4 Code"
author: "Alex Hoagland"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r header}
################################################################################
# I like to include several additional notes in the header of my files here:
#
# Last modified: 8/11/2022
#
### PURPOSE:
  # Lecture 3 code and output file
# 
### NOTES:
  # - uses the Tidyverse package and Dplyr
################################################################################


### 0. Load the packages we will need for this file ####
library(tidyverse) # load the installed package for each new session of R
library(broom)
library(faux) # Useful package for simulating data
library(modelsummary) # For making regression tables
library(causaldata) # Useful toy data sets
library(here) # Helpful in working with directories and projects
library(RM.weights) # this is where our sample data comes from 

set.seed(03262020) # Setting the seed helps to make random number generators give us the same numbers across machines
################################################################################
```

Throughout, we have two examples; first, we have some data on food insecurity that mirrors our case study. Second, we have data on the effect of education on wages for college graduates.

## Scaling and Weighting Regressors

Let's think about what happens when we adjust experience to be in months instead of years. Then, let's weight the regressions.

```{r mydata}
# first, an example with food insecurity 
data("data.FAO_country1")

# base regression
fao_levels <- lm(HUNGRY ~ education + gender + age + urbanrural, data=data.FAO_country1)

# what if we measure age in months? 
data.FAO_country1 <- data.FAO_country1 %>% mutate(age_m = age * 12)
fao_transformed <- lm(HUNGRY ~ education + gender + age_m + urbanrural, data=data.FAO_country1)
msummary(list("Base"=fao_levels, "Age in Months"=fao_transformed),
         stars=c('*' = .1, '**' = .05, '***' = .01), fmt=5) 

# Now what if we weight using the survey weights ("wt")
fao_weighted <- lm(HUNGRY ~ education + gender + age + urbanrural,
                   data=data.FAO_country1, weights=wt)

msummary(list("Base"=fao_levels, "Weighted Regression"=fao_weighted),
         stars=c('*' = .1, '**' = .05, '***' = .01)) # what might we interpret here? 

# and here's the example on college attendance
mydata <- causaldata::close_college

# First pass: regression with education and experience as covariates 
mydata <- mydata %>% mutate(exper_m = exper * 12)
m_levels <- lm(wage ~ educ + exper, data=mydata)
m_transformed <- lm(wage ~ educ + exper_m, data=mydata)

msummary(list("Base"=m_levels, "Months of Experience"=m_transformed),
         stars=c('*' = .1, '**' = .05, '***' = .01)) 
```

## Effect of an outlier in a regression

Even a single outlier can change your regression by a lot! This is why nonlinear transformations can be so useful. This code creates an animation to show the effect of including/excluding a single outlier on a regression:

```{r animate-outliers}
library(gganimate)

# Main data
animatedata <- data.frame(x=rnorm(n=100,mean=5,sd=2))
animatedata <- animatedata %>% mutate(y=-.5*x+rnorm(n=100,mean=0,sd=.25))

# Duplicate each row (for transition in animation)
animatedata <- animatedata %>% bind_rows(animatedata)
animatedata$transition <- 0
animatedata[101:200,]$transition <- 1

# Add (one big) outlier to the second set of data 
animatedata[201,] <- c(20,-20,1) 

# Scatter plot with outlier
ggplot(animatedata,aes(x=x,y=y)) + geom_point() + theme_classic()

# Scatter plot without outlier
animatedata %>% filter(transition == 0) %>% ggplot(aes(x=x,y=y)) + geom_point() + theme_classic()

# To make animated data, need to duplicate rows for all data points in both states (add/subtract only outlier)

animfig <- ggplot(animatedata,aes(x=x,y=y)) + 
  geom_point() + 
  geom_smooth(data=animatedata,aes(x=x,y=y),method='lm') + 
  # Here comes the gganimate code
  transition_states(
    transition,
    transition_length = 1,
    state_length = 1
  ) +
  enter_fade() + 
  exit_shrink() +
  ease_aes('linear') + 
  theme_classic()
animate(animfig)
anim_save(filename=here("RegressionOutlier.gif"),animation=animfig)
```

## Transformed Models

Note: this explores how to use a log transformation in our second context.

```{r mydata}
mydata <- causaldata::close_college

# First pass: simple regression in levels
mydata <- mydata %>% mutate(wage = exp(lwage))
m_levels <- lm(wage ~ educ + exper, data=mydata)

m1 <- lm(lwage ~ educ + exper, data=mydata)
msummary(list("levels"=m_levels, "log_y"=m1),
         stars=c('*' = .1, '**' = .05, '***' = .01)) 
```

## Interaction Terms

Suppose that we think:

-   Maybe the effects of education on HUNGRY differ by gender. Let's use an interaction model to examine heterogeneous treatment effects here. Recall that in an interaction model we need to include **all level terms** of our variables of interest, not just the interactions.

-   But what if we think the returns to education will differ across race?

```{r interactions}
# First example: case study on food security
fao_2 <- lm(HUNGRY ~ education + gender + age + urbanrural + 
              education:gender, 
            data=data.FAO_country1, weight=wt)
msummary(list(fao_levels,fao_2),
         stars=c('*' = .1, '**' = .05, '***' = .01)) 

# What if we had left out the main effect?
fao_3 <- lm(HUNGRY ~ age + urbanrural + 
              education:gender, 
            data=data.FAO_country1, weight=wt)
msummary(list(fao_levels,fao_2, fao_3),
         stars=c('*' = .1, '**' = .05, '***' = .01)) 

# Second example: education and wages
# How does the effect of education differ across race?
m2 <- lm(lwage ~ educ + exper + black + educ:black, data=mydata)
msummary(list(m1,m2),
         stars=c('*' = .1, '**' = .05, '***' = .01)) 

# What if we had left out the main effect?
m3 <- lm(lwage ~ educ + exper + educ:black, data=mydata)
msummary(list(m1,m2,m3),
         stars=c('*' = .1, '**' = .05, '***' = .01)) 
```

## Polynomial Models

What if we think:

-   Age has a nonlinear effect on hunger (why might this be true?)

-   Experience has a nonlinear effect on wages? Why might this be true?

Let's model this nonlinearity by including a squared term in the regression

```{r nonlinear}
ggplot(data=mydata,aes(x=exper,y=lwage)) + geom_point() + 
  theme_minimal() + labs(x="Experience (Years)",y="Wages") + 
  geom_smooth(method='lm', formula= y~x)

# What if we add in a squared term? 
ggplot(data=mydata,aes(x=exper,y=lwage)) + geom_point() + 
  theme_minimal() + labs(x="Experience (Years)",y="Wages") + 
  stat_smooth(method="lm", se=TRUE, fill=NA,
              formula=y ~ poly(x, 2, raw=TRUE),colour="red")
```

How do our results change if we increase the order of the polynomial we fit? Why should/shouldn't we do this?

```{r higher-order}
# What about a cubic term? 
ggplot(data=mydata,aes(x=exper,y=lwage)) + geom_point() + 
  theme_minimal() + labs(x="Experience (Years)",y="Wages") + 
  stat_smooth(method="lm", se=TRUE, fill=NA,
              formula=y ~ poly(x, 3, raw=TRUE),colour="red")

# Higher order terms? 
n <- 10 # You pick a polynomial
ggplot(data=mydata,aes(x=exper,y=lwage)) + geom_point() + 
  theme_minimal() + labs(x="Experience (Years)",y="Wages") + 
  stat_smooth(method="lm", se=TRUE, fill=NA,
              formula=y ~ poly(x, n, raw=TRUE),colour="red")
```

## Standard Errors

### Heteroskedasticity

Let's check if our assumption of homoskedasticity is satisfied.

```{r plot-variance}
mydata <- mydata %>% mutate(wage=exp(lwage))
ggplot(mydata,aes(x=educ,y=wage)) + geom_point() + theme_minimal()
```

Clearly, this assumption fails. Let's implement robust standard errors in our regressions

```{r robust-ses}
m1 <- lm(lwage ~ educ + exper + black + married + nearc4 + educ:black + exper:black, data=mydata)
msummary(list("naive"=m1),
         stars=c('*' = .1, '**' = .05, '***' = .01))

# Same model with robust standard errors
msummary(list("naive"=m1,"robust"=m1),
         vcov=c("classical","robust"),
         stars=c('*' = .1, '**' = .05, '***' = .01))
```

### Clustering

Now, suppose that we have data on geography (US State). What if the returns to education/experience are correlated within states in unique ways? Why might this be true?

```{r clustered-ses}
mydata$state <- unlist(causaldata::abortion[1:3010,1])
m1 <- lm(lwage ~ educ + exper + black + married + nearc4 + educ:black + exper:black, data=mydata)

msummary(list("naive"=m1,"robust"=m1,"Clustered"=m1),
         vcov=c("classical","robust",~state),
         stars=c('*' = .1, '**' = .05, '***' = .01))
```

### Bootstrapping standard errors

For whatever reason, you may need to bootstrap your standard errors. This is a sample code for how you might do that.

```{r bootstrap}
numiter <- 1000 # Number of times you want to sample
sizesample=nrow(mydata) # Size of the sample you want to take

# Create a place to store the coefficients
allbetas <- rep(NA,numiter)

# Run the loop
for (i in 1:numiter) { 
  sampledata <- mydata[sample(nrow(mydata), sizesample,replace=T), ]
  samplemodel <- lm(lwage ~ educ + exper + black + married + nearc4 + educ:black + exper:black, data=sampledata)
  allbetas[i] <- samplemodel$coefficients[2] # Effect of education on lwage
}

# Represent graphically
allbetas <- tibble(allbetas)
ggplot(allbetas,aes(x=allbetas)) + geom_histogram(fill='gray',color="black") + theme_minimal() + 
  labs(x="Estimated Betas",y="Count") + geom_vline(xintercept=0.077,color="red",size=2)

sd(allbetas$allbetas) # This gives us a bootstrapped SE remarkably similar to the regression approach
```

## Package Citations

```{r, include=FALSE}
print("=============================Works Cited=============================")
loadedNamespaces() %>%
map(citation) %>%
print(style = "text") # Adds citations for each package to end of .rmd file

knitr::write_bib(file = 'packages.bib') # Constructs a citation file for all packages used in this lecture.

# DON'T FORGET TO CITE YOUR PACKAGES IN YOUR PAPERS/ASSIGNMENTS. 
```
