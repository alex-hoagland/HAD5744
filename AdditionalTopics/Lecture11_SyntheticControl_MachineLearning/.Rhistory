knitr::opts_chunk$set(echo = TRUE)
################################################################################
# I like to include several additional notes in the header of my files here:
#
# Last modified: 8/15/2022
#
### PURPOSE:
# Lecture 10 code and output file
#
### NOTES:
# - uses the Tidyverse package and Dplyr
################################################################################
### 0. Load the packages we will need for this file ####
library(tidyverse) # load the installed package for each new session of R
library(broom)
library(readxl) # Read in data
library(modelsummary) # For making regression tables
library(causaldata) # Useful toy data sets
library(here) # Helpful in working with directories and projects
library(AER) # this package has lots of applied metrics packages
library(foreign) # Helpful for reading in data from Stata or other code languages
library(zoo) # Helpful packages for organizing dates
library(tidysynth) # For synthetic controls
library(gsynth) # For synthetic controls
library(gghighlight) # For figures
library(lubridate) # For figures
library(stargazer) # For tables
library(quantreg) # For quantile regression
library(binsreg) # For binscatters
library(nprobust) # Local linear regression
set.seed(03262020)
# Setting the seed helps to make random number generators give us the same numbers across machines
################################################################################
mydata <- readRDS(here("weekly_data_2021-06-24.rds"))
# Some descriptive figures
ggplot(mydata, aes(x = last_day,
y = people_fully_vaccinated_per_hundred,
group = state)) +
geom_line() +
gghighlight(state=="OH",
label_params = list(fill = NA, alpha=1)) +
geom_vline(xintercept = lubridate::make_date(2021, 5, 12), linetype = "solid") +
labs(
title = "Vaccination Rates by State by Week",
caption = "Timing of The Ohio Lottery Announcement",
x = "Date",
y = "Percent Fully Vaccinated"
) +
theme_minimal()
# Ranked Vaccination Data
ranks <- mydata %>%
filter(centered_week == 4)  %>%
arrange(desc(people_fully_vaccinated_per_hundred)) %>%
mutate(rank=row_number()) %>%
select(state,people_fully_vaccinated_per_hundred,rank) # Ohio is solidly middle of the pack
# Construct Synthetic Controls
vaccine_out <-
mydata  %>%
# initial the synthetic control object
synthetic_control(outcome = people_fully_vaccinated_per_hundred, # outcome
unit = state, # unit index in the panel data
time = centered_week, # time index in the panel data
i_unit = "OH", # unit where the intervention occurred
i_time = 0, # time period when the intervention occurred
generate_placebos=T # generate placebo synthetic controls (for inference)
) %>%
# Matching on fully vaccinated the weeks before the intervention
generate_predictor(time_window = -17, lagged_vaccinations_week17 = people_fully_vaccinated_per_hundred) %>%
generate_predictor(time_window = -16, lagged_vaccinations_week16 = people_fully_vaccinated_per_hundred) %>%
generate_predictor(time_window = -15, lagged_vaccinations_week15 = people_fully_vaccinated_per_hundred) %>%
generate_predictor(time_window = -14, lagged_vaccinations_week14 = people_fully_vaccinated_per_hundred) %>%
generate_predictor(time_window = -13, lagged_vaccinations_week13 = people_fully_vaccinated_per_hundred) %>%
generate_predictor(time_window = -12, lagged_vaccinations_week12 = people_fully_vaccinated_per_hundred) %>%
generate_predictor(time_window = -11, lagged_vaccinations_week11 = people_fully_vaccinated_per_hundred) %>%
generate_predictor(time_window = -10, lagged_vaccinations_week10 = people_fully_vaccinated_per_hundred) %>%
generate_predictor(time_window = -09, lagged_vaccinations_week09 = people_fully_vaccinated_per_hundred) %>%
generate_predictor(time_window = -08, lagged_vaccinations_week08 = people_fully_vaccinated_per_hundred) %>%
generate_predictor(time_window = -07, lagged_vaccinations_week07 = people_fully_vaccinated_per_hundred) %>%
generate_predictor(time_window = -06, lagged_vaccinations_week06 = people_fully_vaccinated_per_hundred) %>%
generate_predictor(time_window = -05, lagged_vaccinations_week05 = people_fully_vaccinated_per_hundred) %>%
generate_predictor(time_window = -04, lagged_vaccinations_week04 = people_fully_vaccinated_per_hundred) %>%
generate_predictor(time_window = -03, lagged_vaccinations_week03 = people_fully_vaccinated_per_hundred) %>%
generate_predictor(time_window = -02, lagged_vaccinations_week02 = people_fully_vaccinated_per_hundred) %>%
generate_predictor(time_window = -01, lagged_vaccinations_week01 = people_fully_vaccinated_per_hundred) %>%
# Generate the fitted weights for the synthetic control
generate_weights(optimization_window = -17:-1, # time to use in the optimization task
margin_ipop = .02,sigf_ipop = 7,bound_ipop = 6 # optimizer options
) %>%
# Generate the synthetic control
generate_control()
# Which states are we using, and what weights are they given?
vaccine_out %>%
grab_unit_weights() %>%
mutate(weights = round(weight, digits = 4)) %>%
select(unit, weights) %>%
filter(weights>0.0001) %>%
as.data.frame() %>%
stargazer(summary = FALSE, rownames = FALSE)
# What about the independent variables?
vaccine_out %>%
plot_weights() +
labs(title="Synthetic Control Weights")
# Balance Table
vaccine_out %>%
grab_balance_table() %>%
mutate(difference = OH - synthetic_OH) %>%
select(variable, OH, synthetic_OH, difference, donor_sample) %>%
as.data.frame() %>%
stargazer(summary = FALSE, rownames = FALSE,
caption = "Balance Table",
label = "balancetable", type="html") # Note: try this in R Markdown
vaccine_out %>% plot_trends() +
scale_x_continuous(breaks = c(-15,-10,-5,0,5)) +
labs(
title = "Ohio and Synthetic Ohio",
caption = "Timing of The Lottery Announcement",
x="Weeks Relative to Lottery Announcement",
y="Percent Fully Vaccinated"
)
# Plot Model Differences
vaccine_out %>% plot_differences() +
scale_x_continuous(breaks = c(-15,-10,-5,0,5)) +
labs(
title = "Difference between Ohio and Synthetic Ohio",
caption = "Timing of The Lottery Announcement",
x="Weeks Relative to Lottery Announcement",
y="Difference in Percent Fully Vaccinated"
)
# Plot placebos of different states' assignments
vaccine_out %>% plot_placebos() +
scale_x_continuous(breaks = c(-15,-10,-5,0,5)) +
labs(
title = "Difference between State and Synthetic State: All States",
caption = "Timing of The Lottery Announcement",
x="Weeks Relative to Lottery Announcement",
y="Difference in Percent Fully Vaccinated"
)
# This test shifts the pre-treatment window back five weeks.
# This analysis was included in our pre-registration as a demonstration of the
# method and to show that we did not find treatment effects before the lottery
# was announced.
placebo_out <-
mydata %>%
filter(centered_week <= 0) %>%
# initial the synthetic control object
synthetic_control(outcome = people_fully_vaccinated_per_hundred, # outcome
unit = state, # unit index in the panel data
time = centered_week, # time index in the panel data
i_unit = "OH", # unit where the intervention occurred
i_time = -5, # time period when the intervention occurred
generate_placebos=T # generate placebo synthetic controls (for inference)
) %>%
# Matching on fully vaccination the weeks before the intervention
generate_predictor(time_window = -17, people_fully_vaccinated_per_hundred17 = people_fully_vaccinated_per_hundred) %>%
generate_predictor(time_window = -16, people_fully_vaccinated_per_hundred16 = people_fully_vaccinated_per_hundred) %>%
generate_predictor(time_window = -15, people_fully_vaccinated_per_hundred15 = people_fully_vaccinated_per_hundred) %>%
generate_predictor(time_window = -14, people_fully_vaccinated_per_hundred14 = people_fully_vaccinated_per_hundred) %>%
generate_predictor(time_window = -13, people_fully_vaccinated_per_hundred13 = people_fully_vaccinated_per_hundred) %>%
generate_predictor(time_window = -12, people_fully_vaccinated_per_hundred12 = people_fully_vaccinated_per_hundred) %>%
generate_predictor(time_window = -11, people_fully_vaccinated_per_hundred11 = people_fully_vaccinated_per_hundred) %>%
generate_predictor(time_window = -10, people_fully_vaccinated_per_hundred10 = people_fully_vaccinated_per_hundred) %>%
generate_predictor(time_window = -09, people_fully_vaccinated_per_hundred09 = people_fully_vaccinated_per_hundred) %>%
generate_predictor(time_window = -08, people_fully_vaccinated_per_hundred08 = people_fully_vaccinated_per_hundred) %>%
generate_predictor(time_window = -07, people_fully_vaccinated_per_hundred07 = people_fully_vaccinated_per_hundred) %>%
generate_predictor(time_window = -06, people_fully_vaccinated_per_hundred06 = people_fully_vaccinated_per_hundred) %>%
# Generate the fitted weights for the synthetic control
generate_weights(optimization_window = -17:-6, # time to use in the optimization task
margin_ipop = .02,sigf_ipop = 7,bound_ipop = 6 # optimizer options
) %>%
# Generate the synthetic control
generate_control()
placebo_out %>% plot_trends()  +
labs(
title = "Placebo Analysis: Ohio and Synthetic Ohio",
caption = "Timing of The Placebo Announcement",
x="Weeks Relative to Lottery Announcement",
y="Percent Fully Vaccinated"
)
placebo_out %>% plot_differences()  +
labs(
title = "Placebo Analysis:  Difference between Ohio and Synthetic Ohio",
caption = "Timing of The Placebo Announcement",
x="Weeks Relative to Lottery Announcement",
y="Percent Fully Vaccinated"
)
placebo_out %>% grab_signficance() %>% filter(unit_name=="OH")
?grab_significance
placebo_out
placebo_out %>% filter(unit_name == "OH")
placebo_out %>% filter(.id == "OH")
library(tidysynth)
tidysynth::grab_significance()
placebo_out %>% grab_signficance() %>% filter(unit_name=="OH")
placebo_out %>% tidysynth::grab_signficance() %>% filter(unit_name=="OH")
grab_significance(placebo_out)
grab_signficance(placebo_out)
tidysynth::grab_signficance(placebo_out)
placebo_out %>% grab_significance()
placebo_out %>% grab_significance() %>% filter(unit_name == "OH")
placebo_out %>% grab_significance() %>% filter(unit_name == "OH")
# This was giving me problems, needed to run in the console
# placebo_out %>% grab_significance() %>% filter(unit_name == "OH")
placebo_out %>% grab_unit_weights() %>% arrange(desc(weight))
placebo_out %>% plot_mspe_ratio()
# New data: health expenditures
mydata <- read.dta(here("heus_mepssample.dta")) # An extract from MEPS
hist(mydata$exp_tot) # Why does this look backwards from the figure we just showed on slides?
# OLS Regression: What is the effect of activity limitation on spending?
m_ols <- lm(exp_tot ~ anylim + age + female + race_bl + race_oth +eth_hisp + famsize + ed_hs + ed_hsplus + ed_col + lninc + reg_midw + reg_south + reg_west + ins_mcare + ins_mcaid + ins_unins + ins_dent,
data=mydata,
weights=wtdper) # Note the use of weights
msummary(list("OLS"=m_ols),
vcov=c(rep("robust",1)),
stars=c('*' = .1, '**' = .05, '***' = .01))
# At the mean: activity limitation is associated with $4000 increase in spending
summary(mydata$exp_tot) # How to interpret this?
plot(m_ols) # QQ plot -- shows that the distribution is highly nonnormal
m_lad <- rq(exp_tot ~ anylim + age + female + race_bl + race_oth +eth_hisp + famsize + ed_hs + ed_hsplus + ed_col + lninc + reg_midw + reg_south + reg_west + ins_mcare + ins_mcaid + ins_unins + ins_dent,
data=mydata,
weights=wtdper,
tau = 0.5)
msummary(list("OLS"=m_ols,"LAD"=m_lad),
stars=c('*' = .1, '**' = .05, '***' = .01))
mytau <- rep(NA,10) # empty vector: quantiles
coefs <- rep(NA, 10) # empty vector: coefficients
lb <- rep(NA, 10) # empty vector: 95% LB
ub <- rep(NA, 10) # empty vector: 95% UB
for (t in 1:10) {
mytau[t] <- t/10 # indicate which decile I am using
print(paste0("Considering quantile ",mytau[t],sep=" "))
myreg <- rq(exp_tot ~ anylim + age + female + race_bl + race_oth +eth_hisp + famsize + ed_hs + ed_hsplus + ed_col + lninc + reg_midw + reg_south + reg_west + ins_mcare + ins_mcaid + ins_unins + ins_dent,
data=mydata,
weights=wtdper, # use survey weights (not relevant to qr)
tau = mytau[t]) # tau ranges from 0 to 1
coefs[t] <- myreg$coefficients[2]
mysum <- summary(myreg)
lb[t] <- coefs[t]-1.96*mysum$coefficients[2,2]
ub[t] <- coefs[t]+1.96*mysum$coefficients[2,2]
}
# Construct a figure of coefficients across distribution
plotdata <- data.frame(mytau,coefs,lb,ub)
plotdata %>%ggplot(aes(x=mytau))+
geom_point(aes(y=coefs),size=2,color='blue') +
geom_errorbar(aes(ymin = lb, ymax = ub),width=0.03) +
scale_y_continuous(labels=scales::dollar_format()) +
theme_classic() + labs(x="Quantile", y="Estimated Marginal Effect of Activity Limitation on Health Spending")
plotdata %>% filter(mytau < 1) %>% ggplot(aes(x=mytau))+
geom_point(aes(y=coefs),size=2,color='blue') +
geom_errorbar(aes(ymin = lb, ymax = ub),width=0.03) +
scale_y_continuous(labels=scales::dollar_format()) +
theme_classic() + labs(x="Quantile", y="Estimated Marginal Effect of Activity Limitation on Health Spending")
myquants <- quantile(mydata$exp_tot,probs=c(0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1),na.rm=TRUE)
plotdata %>% mutate(coefs = coefs / myquants,
lb = lb / myquants,
ub = ub / myquants) %>%
ggplot(aes(x=mytau))+
geom_point(aes(y=coefs),size=2,color='blue') +
geom_errorbar(aes(ymin = lb, ymax = ub),width=0.03) +
geom_hline(yintercept=1,color='red',linetype='dashed') +
theme_classic() + labs(x="Quantile", y="Estimated Marginal Effect of Activity Limitation on Health Spending")
# How do we interpret this figure?
# Check this site for helpful coding tips for nonparametric techniques: https://nppackages.github.io/
# Binscatter: relationship between income and spending
mydata %>% ggplot(aes(x=lninc,y=exp_tot)) +
geom_point() +
theme_classic() +
scale_y_continuous(labels=scales::dollar_format()) +
labs(x="Log(Income)",y="Total Health Expenditures") # This is hard to interpret
# Let's bin the data more
binsreg(y=exp_tot,x=lninc,
w= ~ age + female + race_bl + eth_hisp + famsize + ed_col + ed_hsplus, # Any control variables we want
data=mydata,
line=c(3,3), # Do we want a smoothed line?
ci=c(3,3)) # If we want any confidence intervals on points
# Now we can add the local polynomial regression
# Note that this will add weights to data, which are all clustered
binsreg(y=exp_tot,x=lninc,
w= ~ age + female + race_bl + eth_hisp + famsize + ed_col + ed_hsplus, # Any control variables we want
data=mydata,
polyreg=3,
ci=c(3,3)) # If we want any confidence intervals on points
# Clean out NA observations
mydata <- mydata %>% filter(!is.na(mydata$lninc)) %>% filter(!is.na(mydata$exp_tot))
regdata <- mydata %>% sample_n(5000) # speed up estimation by sampling some of the data
m1 <- lprobust(y=regdata$exp_tot,x=regdata$lninc,
neval = 30, # how many bins should we use
p = 3, # max. polynomial order
level=95, # confidence interval desired
kernel = 'epa') # note: don't pub anything for h and b, there are companion commands for optimal bandwidth selectors
summary(m1) # estimates across distribution of lninc
nprobust.plot(m1) #
