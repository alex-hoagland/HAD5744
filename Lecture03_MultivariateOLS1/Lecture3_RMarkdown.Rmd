---
title: "Lecture 3 Code"
author: "Alex Hoagland"
date: "`r Sys.Date()`"
output:
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r header}
################################################################################
# I like to include several additional notes in the header of my files here:
#
# Last modified: 8/11/2022
#
### PURPOSE:
  # Lecture 3 code and output file
# 
### NOTES:
  # - uses the Tidyverse package and Dplyr
################################################################################


### 0. Load the packages we will need for this file ####
library(tidyverse) # load the installed package for each new session of R
library(broom)
library(faux) # Useful package for simulating data
library(modelsummary) # For making regression tables
library(causaldata) # Useful toy data sets
library(here) # Helpful in working with directories and projects
library(dotwhisker) # For coefficient plots
library(gapminder) # For coefficient plots

set.seed(122333) # Setting the seed helps to make random number generators give us the same numbers across machines
################################################################################
```

## Control Variables

First, let's explore the relationship between crop loss and child health. We'll use some fake data for this, so don't trust any of the results you see reported here! 

```{r fake-data,echo=F}
# Create a data set of 10000 children, with some measures of health, shocks, and income

# first, start with the independent variables 
mydata <- data.frame(income = rlnorm(n=10000,8,1.5)) # income

# add in shocks as a binary indicator that occurs with probability 0.2 if income is below average and 0.1 if income is above average
mydata <- mydata %>% mutate(shock = runif(n=10000,0,1)) %>% mutate(medinc = median(income))
mydata <- mydata %>% mutate(croploss = ifelse(shock < 0.2 & income <= medinc, 1, 
                                              ifelse(shock < 0.1 & income >= medinc, 1, 0)))

# define a "true" model 
mydata <- mydata %>% mutate(shock = rnorm(n=10000, 0, 3))
mydata <- mydata %>% mutate(health = -1-0.479*croploss+0.25*income+shock) %>% 
  select(-c(shock))

view(mydata) # this command lets us look at the data (but we don't want it to print out into the rmd, hence the echo=F)
```

### How do controls change the results?

If we don't include controls, we get a simple regression: 
```{r simple}
lm_simple <- lm(health ~ croploss, data=mydata)
summary(lm_simple)
```

But if we control for income, the results change: 

```{r control-education}
# Now, control for income 
lm_complex <- lm(health ~ croploss + income, data=mydata)
summary(lm_complex)
```

How can we visualize these regressions? Let's use a coefficient plot! 
```{r coefplot}
dwplot(list(lm_simple,lm_complex)) # how can you customize this? 
# a tutorial: https://felixhaass.github.io/dataviz_ggplot2/session4.html

# To customize, let's combine our models as objects
m1_tidy <- tidy(lm_simple) %>% 
  mutate(model = "Baseline")

# repeat for model 2
m2_tidy <- tidy(lm_complex) %>% 
  mutate(model = "Additional Controls")

# "glue" model data frames together
all_models <- bind_rows(m1_tidy, m2_tidy) %>% 
  filter(term != "(Intercept)") %>% # remove the intercept
  relabel_predictors(c(croploss = "Crop Loss Shock", 
                       income = "Household Income"))

# An example of customization (compare with slides)
dwplot(all_models, 
       # here are our regular aesthetics
       dot_args = list(aes(colour = model, 
                       shape = model, size=1.2)), 
       whisker_args = list(size=1)) + 
  theme_bw() +
  labs(title = "Predicting Child Health Outcomes", 
       x = "Coefficient Estimate with 95% CIs", 
       y = "", size="") +
  geom_vline(xintercept = 0, linetype = "dashed", size=1) +
  theme(plot.title = element_text(face="bold"),
        legend.position = "bottom",
        legend.background = element_rect(colour="grey80"),
        legend.title.align = .5) +
  guides(size = "none") + # remove the size legend
  scale_shape_discrete(name  ="Models", breaks = c(0, 1)) + # breaks assign shapes
  scale_color_discrete(type=c("#E69F00", "#56B4E9"),name = "Models") # breaks assign colors
# ggsave(here("coefplot.png"), width = 8, height = 6, dpi = 300) # save the plot
```

## Dummy Variables

Let's add another control in the form of a dummy variable: child indigenous identity.

```{r unorganized}
mydata <- mydata %>% mutate(indig = ifelse(runif(nrow(mydata))>0.85, 1, 0),
                            nindig = 1-indig)

# What is the composition of our sample?
summary(mydata$indig)
```

Now let's include this dummy variable in the regression, and compare all three results in a regression table using modelsummary 

```{r dummy-reg}
# Linear model with dummy variable included
lm_dummy <- lm(health ~ croploss + income + indig, data=mydata)
summary(lm_dummy) # What does it mean that this is significant? Should it be? 
  # Return to this at the end of the lecture when we talk about validity traps

# Let's make a regression table for ease of interpretation
msummary(list("Simple"=lm_simple,"One Control"=lm_complex,"Full"=lm_dummy),
         stars=c('*' = .1, '**' = .05, '***' = .01))
```

### Dummy Variable Trap

What happens if we include both $1\{indig\}$ and $1\{not indig\}$ in a regression? 

```{r dvt}
lm_dummytrap <- lm(health ~ croploss + income + indig + nindig, data=mydata)
summary(lm_dummytrap)
  # Code can usually detect the dummy variable trap, but don't count on it! 
```

### Multiple dummy variables

Finally, how does this change if we have multiple dummy variables in a set? Let's consider the region in which each child lives.

```{r region} 
mydata <- mydata %>% mutate(region = sample(seq(1:4),size=nrow(mydata),replace=TRUE)) 
  # Generate a random region variable  

# Suppose that 1=West, 2=Midwest, 3=South, 4=East
# Need to generate three dummy variables for the regression 
mydata <- mydata %>% mutate(region_west = (region == 1), 
                      region_midwest = (region == 2), 
                      region_south = (region == 3))
lm_region <- lm(health ~ croploss + income + indig + region_west + region_midwest + region_south, data=mydata)
msummary(list("No Regions"=lm_dummy, "With Region Controls"=lm_region),
         stars=c('*' = .1, '**' = .05, '***' = .01)) 
  # Why aren't our other coefficients changed? Thoughts? 

# # Joint test of significance -- helpful to consider after lecture
# library('lmtest')
# lmtest::waldtest(lm_dummy, lm_region) # Run a version of the regression without the variables you want to test, 
# # and one with full set of coefficients. Then use waldtest to test difference
```

## Making a Regression Table

### Preliminaries 

When making and saving outputs, you want your code (and outputs) to be **completely replicable**. You will absolutely have to make these figures and tables more times than you think you should reasonably have to! 

So make sure you have: 
1. An R project set up
2. A command that points R to a directory **regardless of your machine** 
    a. This is where the "here" package comes in handy
3. Consistent project organization (folders) with dates for each replication of a figure

```{r reg-tables}
# Make sure your directory is working
here() # Note: this will be the directory your project is stored in

# Some sample data for our table construction
res <- causaldata::restaurant_inspections

res <- res %>%
  # Create NumberofLocations
  group_by(business_name) %>%
  mutate(NumberofLocations = n())
summary(res$NumberofLocations)

## Let's run our regression models
m1 <- lm(inspection_score ~ NumberofLocations, data = res)
m2 <- lm(inspection_score ~ NumberofLocations + Year + Weekend, data = res)

# Give msummary a list() of the models we want in our table
# and save to a file using the here() library
# Note that you select the file type (html, pdf, etc.)
# (see help(msummary) for other options)
gm <- tibble::tribble(
  ~raw,        ~clean,          ~fmt,
  "nobs",      "N",             0)

msummary(list("Simple"=m1,"Full"=m2), # Rename columns
         stars=TRUE, # Include stars for statistical significance
         fmt = 2, # how many decimal places do you want? 
        coef_rename = c("(Intercept)" = "Intercept", 
                        "NumberofLocations" = "Number of Locations", 
                        "Year" = "Year", 
                        "WeekendTRUE" = "Inspection on a Weekend"), # Rename the rows
        gof_omit = 'DF|Deviance|RMSE|AIC|BIC|Log.Lik', # Omit some of the goodness of fit stats
        gof_map = gm) # If you just want to include N here (how could you add in, say, R2?)
         # output= here('regression_table.html')) 
# If you want a folder within your directory, you would say here("Output", "RegressionTable.html")

# Default significance stars are +/*/**/*** .1/.05/.01/.001. Social science
# standard */**/*** .1/.05/.01 can be restored with stars=c('*' = .1, '**' = .05, '***' = .01)
```

## Package Citations
```{r, include=FALSE}
print("=============================Works Cited=============================")
loadedNamespaces() %>%
map(citation) %>%
print(style = "text") # Adds citations for each package to end of .rmd file

knitr::write_bib(file = 'packages.bib') # Constructs a citation file for all packages used in this lecture.

# DON'T FORGET TO CITE YOUR PACKAGES IN YOUR PAPERS/ASSIGNMENTS. 
```